\chapter{Conclusion}
This thesis set out to evaluate emotion recognition methods suitable for resource-constrained robots, focusing specifically on facial emotion recognition and text-based sentiment analysis. It aimed to assess the accuracy and efficiency of different face detection and facial emotion classification models and to explore how off-the-shelf sentiment analysis tools could supplement emotion detection when visual input is limited or unavailable. Through comparative evaluation across multiple platforms, including robotic hardware, the study met its objectives by identifying optimal model combinations for real-time deployment, clarifying the trade-offs between speed and accuracy, and demonstrating how each modality can operate independently to support more flexible emotion-aware interactions.

The project contributes to the field in several key ways. First, it offers a comparative evaluation of widely used face detection and emotion recognition models in the context of robotic deployment, providing insight into the trade-offs between speed and accuracy. Second, it shows the potential of deploying facial and sentiment analysis systems in parallel to improve system robustness. The work also demonstrates that cloud-based processing can be effective in the short term, while identifying the limitations this approach introduces, especially regarding latency and real-time performance. Together, these contributions lay the groundwork for more responsive, emotionally aware human-robot interactions.

Future work will involve extending this system beyond controlled test environments. In particular, the next phase will focus on evaluating the system's performance in live interactions with human participants and in dynamic, real-world settings. This will help assess its practical effectiveness and identify usability issues or technical constraints not evident during initial testing. Further developments will also include integrating audio emotion recognition directly onto the robotic platform to reduce reliance on cloud services and improve real-time responsiveness. In addition, exploring multimodal fusion techniques, advanced facial analysis methods, and data augmentation strategies will be critical for increasing recognition accuracy and robustness across varying conditions.

In summary, this thesis has delivered on its aim of developing a functional multimodal emotion recognition system, provided meaningful contributions to the field of affective robotics, and identified several promising directions for future advancement.
